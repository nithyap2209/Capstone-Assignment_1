{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pymongo\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API Key connection\n",
    "def Api_connect():\n",
    "    Api_Id=\"AIzaSyAcjVgviPYjTebH5GkKPOSHNFA7Xnl-2Ac\"\n",
    "    \n",
    "    api_service_name=\"youtube\"\n",
    "    api_version=\"v3\"\n",
    "\n",
    "    youtube=build(api_service_name, api_version, developerKey = Api_Id)\n",
    "    return youtube\n",
    "youtube=Api_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Channels information\n",
    "# def get_channel_info(channel_id):\n",
    "    \n",
    "#     request = youtube.channels().list(\n",
    "#                 part = \"snippet,contentDetails,Statistics\",\n",
    "#                 id = channel_id)\n",
    "            \n",
    "#     response1=request.execute()\n",
    "\n",
    "#     for i in range(0,len(response1[\"items\"])):\n",
    "#         data = dict(\n",
    "#                     Channel_Name = response1[\"items\"][i][\"snippet\"][\"title\"],\n",
    "#                     Channel_ID = response1[\"items\"][i][\"id\"],\n",
    "#                     subscribers= response1[\"items\"][i][\"statistics\"][\"subscriberCount\"],\n",
    "#                     Views = response1[\"items\"][i][\"statistics\"][\"viewCount\"],\n",
    "#                     Total_vedio = response1[\"items\"][i][\"statistics\"][\"videoCount\"],\n",
    "#                     Channel_Description = response1[\"items\"][i][\"snippet\"][\"description\"],\n",
    "#                     Playlist_ID = response1[\"items\"][i][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"],\n",
    "#                     )\n",
    "#         return data\n",
    "    \n",
    "def get_channel_info(channel_id):\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=channel_id\n",
    "    )\n",
    "\n",
    "    response = request.execute()\n",
    "\n",
    "    if \"items\" in response and len(response[\"items\"]) > 0:\n",
    "        item = response[\"items\"][0]  \n",
    "        data = {\n",
    "            \"Channel_Name\": item[\"snippet\"][\"title\"],\n",
    "            \"Channel_ID\": item[\"id\"],\n",
    "            \"Subscribers\": item[\"statistics\"][\"subscriberCount\"],\n",
    "            \"Views\": item[\"statistics\"][\"viewCount\"],\n",
    "            \"Total_Videos\": item[\"statistics\"][\"videoCount\"],\n",
    "            \"Channel_Description\": item[\"snippet\"][\"description\"],\n",
    "            \"Playlist_ID\": item[\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"],\n",
    "        }\n",
    "        return data\n",
    "    else:\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_details=get_channel_info(\"UCduIoIMfD8tT3KoU0-zBRgQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get video ids\n",
    "def get_channel_videos(channel_id):\n",
    "    video_ids = []\n",
    "    # get Uploads playlist id\n",
    "    res = youtube.channels().list(id=channel_id, \n",
    "                                  part='contentDetails').execute()\n",
    "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    next_page_token = None\n",
    "    \n",
    "    while True:\n",
    "        res = youtube.playlistItems().list( \n",
    "                                           part = 'snippet',\n",
    "                                           playlistId = playlist_id, \n",
    "                                           maxResults = 50,\n",
    "                                           pageToken = next_page_token).execute()\n",
    "        \n",
    "        for i in range(len(res['items'])):\n",
    "            video_ids.append(res['items'][i]['snippet']['resourceId']['videoId'])\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "        \n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video_Ids=get_channel_videos(\"UCduIoIMfD8tT3KoU0-zBRgQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video_Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get video information\n",
    "def get_video_info(video_ids):\n",
    "\n",
    "    video_data = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(\n",
    "                    part=\"snippet,contentDetails,statistics\",\n",
    "                    id= video_id)\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response[\"items\"]:\n",
    "            data = dict(Channel_Name = item['snippet']['channelTitle'],\n",
    "                        Channel_Id = item['snippet']['channelId'],\n",
    "                        Video_Id = item['id'],\n",
    "                        Title = item['snippet']['title'],\n",
    "                        Tags = item['snippet'].get('tags'),\n",
    "                        Thumbnail = item['snippet']['thumbnails']['default']['url'],\n",
    "                        Description = item['snippet']['description'],\n",
    "                        Published_Date = item['snippet']['publishedAt'],\n",
    "                        Duration = item['contentDetails']['duration'],\n",
    "                        Views = item['statistics']['viewCount'],\n",
    "                        Likes = item['statistics'].get('likeCount'),\n",
    "                        Comments = item['statistics'].get('commentCount'),\n",
    "                        Favorite_Count = item['statistics']['favoriteCount'],\n",
    "                        Definition = item['contentDetails']['definition'],\n",
    "                        Caption_Status = item['contentDetails']['caption']\n",
    "                        )\n",
    "            video_data.append(data)\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_details=get_video_info(Video_Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get comment information\n",
    "def get_comment_info(video_ids):\n",
    "        Comment_Information = []\n",
    "        try:\n",
    "                for video_id in video_ids:\n",
    "\n",
    "                        request = youtube.commentThreads().list(\n",
    "                                part = \"snippet\",\n",
    "                                videoId = video_id,\n",
    "                                maxResults = 50\n",
    "                                )\n",
    "                        response5 = request.execute()\n",
    "                        \n",
    "                        for item in response5[\"items\"]:\n",
    "                                comment_information = dict(\n",
    "                                        Comment_Id = item[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
    "                                        Video_Id = item[\"snippet\"][\"videoId\"],\n",
    "                                        Comment_Text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"],\n",
    "                                        Comment_Author = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"],\n",
    "                                        Comment_Published = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"])\n",
    "\n",
    "                                Comment_Information.append(comment_information)\n",
    "        except:\n",
    "                pass\n",
    "                \n",
    "        return Comment_Information\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment_detail=get_comment_info(Video_Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get playlist ids\n",
    "def get_playlist_info(channel_id):\n",
    "    All_data = []\n",
    "    next_page_token = None\n",
    "    next_page = True\n",
    "    while next_page:\n",
    "\n",
    "        request = youtube.playlists().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token\n",
    "            )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']: \n",
    "            data={'Playlist_Id':item['id'],\n",
    "                    'Title':item['snippet']['title'],\n",
    "                    'Channel_Id':item['snippet']['channelId'],\n",
    "                    'Channel_Name':item['snippet']['channelTitle'],\n",
    "                    'PublishedAt':item['snippet']['publishedAt'],\n",
    "                    'Video_Count':item['contentDetails']['itemCount']}\n",
    "            All_data.append(data)\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "            next_page=False\n",
    "    return All_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_details= get_playlist_info(\"UCduIoIMfD8tT3KoU0-zBRgQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload to mongoDB\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://Nithya:nithya@cluster0.zgxu6ax.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db=client['Youtube_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def channel_details(channel_id):\n",
    "    ch_details = get_channel_info(channel_id)\n",
    "    pl_details = get_playlist_info(channel_id)\n",
    "    vi_ids = get_channel_videos(channel_id)\n",
    "    vi_details = get_video_info(vi_ids)\n",
    "    com_details = get_comment_info(vi_ids)\n",
    "\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    coll1.insert_one({\"channel_information\":ch_details,\"playlist_information\":pl_details,\"video_information\":vi_details,\n",
    "                     \"comment_information\":com_details})\n",
    "    \n",
    "    return \"upload completed successfully\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert = channel_details(\"UCduIoIMfD8tT3KoU0-zBRgQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert = channel_details(\"UCY6KjrDBN_tIRFT_QNqQbRQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"nithya\",\n",
    "        database= \"youtube_data\",\n",
    "        port = \"5432\"\n",
    "        )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "drop_query = \"drop table if exists channels\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "try:\n",
    "    create_query = '''create table if not exists channels(Channel_Name varchar(100),\n",
    "                    Channel_ID varchar(80) primary key, \n",
    "                    subscribers bigint, \n",
    "                    Views bigint,\n",
    "                    Total_vedio int,\n",
    "                    Channel_Description text,\n",
    "                    Playlist_ID varchar(50))'''\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "except:\n",
    "    st.write(\"Channels Table alredy created\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_list = []\n",
    "db = client[\"Youtube_data\"]\n",
    "coll1 = db[\"channel_details\"]\n",
    "for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "    ch_list.append(ch_data[\"channel_information\"])\n",
    "df = pd.DataFrame(ch_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_Name</th>\n",
       "      <th>Channel_ID</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>Views</th>\n",
       "      <th>Total_vedio</th>\n",
       "      <th>Channel_Description</th>\n",
       "      <th>Playlist_ID</th>\n",
       "      <th>Subscribers</th>\n",
       "      <th>Total_Videos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GUVI</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>193000</td>\n",
       "      <td>3679671</td>\n",
       "      <td>1372</td>\n",
       "      <td>GUVI is an IIT-M &amp; IIM-A incubated edu-tech co...</td>\n",
       "      <td>UUduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1860335503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Common Man! MG Squad 🖖🏻</td>\n",
       "      <td>UUY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>7240000</td>\n",
       "      <td>2601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel_Name                Channel_ID subscribers       Views Total_vedio  \\\n",
       "0         GUVI  UCduIoIMfD8tT3KoU0-zBRgQ      193000     3679671        1372   \n",
       "1  Madan Gowri  UCY6KjrDBN_tIRFT_QNqQbRQ         NaN  1860335503         NaN   \n",
       "\n",
       "                                 Channel_Description  \\\n",
       "0  GUVI is an IIT-M & IIM-A incubated edu-tech co...   \n",
       "1                            Common Man! MG Squad 🖖🏻   \n",
       "\n",
       "                Playlist_ID Subscribers Total_Videos  \n",
       "0  UUduIoIMfD8tT3KoU0-zBRgQ         NaN          NaN  \n",
       "1  UUY6KjrDBN_tIRFT_QNqQbRQ     7240000         2601  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df.iterrows():\n",
    "        insert_query = '''INSERT into channels(Channel_Name,\n",
    "                                                    Channel_ID,\n",
    "                                                    subscribers,\n",
    "                                                    Views,\n",
    "                                                    Total_vedio,\n",
    "                                                    Channel_Description,\n",
    "                                                    Playlist_ID)\n",
    "                                        VALUES(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "            \n",
    "\n",
    "        values =(\n",
    "                row['Channel_Name'],\n",
    "                row['Channel_ID'],\n",
    "                row['subscribers'],\n",
    "                row['Views'],\n",
    "                row['Total_vedio'],\n",
    "                row['Channel_Description'],\n",
    "                row['Playlist_ID'])\n",
    "        try:                     \n",
    "            cursor.execute(insert_query,values)\n",
    "            mydb.commit()    \n",
    "        except:\n",
    "            st.write(\"Channels values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Channel_Name', 'Channel_ID', 'subscribers', 'Views', 'Total_vedio',\n",
      "       'Channel_Description', 'Playlist_ID', 'Subscribers', 'Total_Videos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channels_table():\n",
    "    mydb = psycopg2.connect(host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"nithya\",\n",
    "        database= \"youtube_data\",\n",
    "        port = \"5432\"\n",
    "        )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    drop_query = \"drop table if exists channels\"\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = '''create table if not exists channels(Channel_Name varchar(100),\n",
    "                        Channel_ID varchar(80) primary key, \n",
    "                        subscribers bigint, \n",
    "                        Views bigint,\n",
    "                        Total_vedio int,\n",
    "                        Channel_Description text,\n",
    "                        Playlist_ID varchar(50))'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"Channels Table alredy created\")    \n",
    "\n",
    "    ch_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"channel_information\"])\n",
    "    df = pd.DataFrame(ch_list)\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        insert_query = '''INSERT into channels(Channel_Name,\n",
    "                                                    Channel_ID,\n",
    "                                                    subscribers,\n",
    "                                                    Views,\n",
    "                                                    Total_vedio,\n",
    "                                                    Channel_Description,\n",
    "                                                    Playlist_ID)\n",
    "                                        VALUES(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "            \n",
    "\n",
    "        values =(\n",
    "                row['Channel_Name'],\n",
    "                row['Channel_ID'],\n",
    "                row['subscribers'],\n",
    "                row['Views'],\n",
    "                row['Total_vedio'],\n",
    "                row['Channel_Description'],\n",
    "                row['Playlist_ID'])\n",
    "    try:                     \n",
    "        cursor.execute(insert_query,values)\n",
    "        mydb.commit()    \n",
    "    except:\n",
    "        st.write(\"Channels values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"nithya\",\n",
    "        database= \"youtube_data\",\n",
    "        port = \"5432\"\n",
    "        )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "drop_query = \"drop table if exists playlists\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "try:\n",
    "    create_query = '''create table if not exists playlists(Playlist_Id varchar(100) primary key,\n",
    "                    Title varchar(80), \n",
    "                    Channel_Id varchar(100), \n",
    "                    Channel_Name varchar(100),\n",
    "                    PublishedAt timestamp,\n",
    "                    Video_Count int\n",
    "                    )'''\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "except:\n",
    "    st.write(\"Playlists Table alredy created\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_list = []\n",
    "db = client[\"Youtube_data\"]\n",
    "coll1 =db[\"channel_details\"]\n",
    "for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "    for i in range(len(pl_data[\"playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "df1 = pd.DataFrame(pl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Playlist_Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Channel_Id</th>\n",
       "      <th>Channel_Name</th>\n",
       "      <th>PublishedAt</th>\n",
       "      <th>Video_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PL_9uM5be2amoGVT5rqGXFRdQz6Gqu9sWN</td>\n",
       "      <td>Top 10 Tech News of the week</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>GUVI</td>\n",
       "      <td>2023-12-15T10:52:09Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL_9uM5be2amqgdHCG_OStCR8dddQaiR__</td>\n",
       "      <td>AI For India 2.0 Webinars</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>GUVI</td>\n",
       "      <td>2023-08-10T07:12:04Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PL_9uM5be2amoedmRrYq7A6rkqL95SuPVq</td>\n",
       "      <td>AI for India 2.0</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>GUVI</td>\n",
       "      <td>2023-07-20T12:46:29Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PL_9uM5be2ampk5Vh5WN7mi-VAOjUF8qD5</td>\n",
       "      <td>Design Series | GUVI</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>GUVI</td>\n",
       "      <td>2023-07-19T07:00:35Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PL_9uM5be2amq7piq6uTztjw67PGRUi7Ug</td>\n",
       "      <td>All about HR</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>GUVI</td>\n",
       "      <td>2023-07-13T11:01:20Z</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>PLeEP84ImH_Lux9xwLCDjsk1SisM5AP316</td>\n",
       "      <td>Madan Gowri Talks</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>2017-03-28T10:03:58Z</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>PLeEP84ImH_LsRNVOjWuDwnj_SvJaJzX3i</td>\n",
       "      <td>History | Tamil | MADAN GOWRI</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>2016-10-13T19:01:39Z</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>PLeEP84ImH_LucQAg7_dsRDsXrZvijCgkK</td>\n",
       "      <td>Social cause | English</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>2016-09-20T16:26:29Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>PLeEP84ImH_LuGuANs4wjBY5UkvhpuQfFQ</td>\n",
       "      <td>Tamil | Business Vlog</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>2016-09-20T16:23:02Z</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>PLeEP84ImH_LtBlaGKctUheYQ4IQZnNLsY</td>\n",
       "      <td>Social Awareness | Tamil</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>2016-09-20T16:03:11Z</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Playlist_Id                          Title  \\\n",
       "0    PL_9uM5be2amoGVT5rqGXFRdQz6Gqu9sWN   Top 10 Tech News of the week   \n",
       "1    PL_9uM5be2amqgdHCG_OStCR8dddQaiR__      AI For India 2.0 Webinars   \n",
       "2    PL_9uM5be2amoedmRrYq7A6rkqL95SuPVq               AI for India 2.0   \n",
       "3    PL_9uM5be2ampk5Vh5WN7mi-VAOjUF8qD5           Design Series | GUVI   \n",
       "4    PL_9uM5be2amq7piq6uTztjw67PGRUi7Ug                   All about HR   \n",
       "..                                  ...                            ...   \n",
       "146  PLeEP84ImH_Lux9xwLCDjsk1SisM5AP316              Madan Gowri Talks   \n",
       "147  PLeEP84ImH_LsRNVOjWuDwnj_SvJaJzX3i  History | Tamil | MADAN GOWRI   \n",
       "148  PLeEP84ImH_LucQAg7_dsRDsXrZvijCgkK         Social cause | English   \n",
       "149  PLeEP84ImH_LuGuANs4wjBY5UkvhpuQfFQ          Tamil | Business Vlog   \n",
       "150  PLeEP84ImH_LtBlaGKctUheYQ4IQZnNLsY       Social Awareness | Tamil   \n",
       "\n",
       "                   Channel_Id Channel_Name           PublishedAt  Video_Count  \n",
       "0    UCduIoIMfD8tT3KoU0-zBRgQ         GUVI  2023-12-15T10:52:09Z            2  \n",
       "1    UCduIoIMfD8tT3KoU0-zBRgQ         GUVI  2023-08-10T07:12:04Z            2  \n",
       "2    UCduIoIMfD8tT3KoU0-zBRgQ         GUVI  2023-07-20T12:46:29Z            2  \n",
       "3    UCduIoIMfD8tT3KoU0-zBRgQ         GUVI  2023-07-19T07:00:35Z            4  \n",
       "4    UCduIoIMfD8tT3KoU0-zBRgQ         GUVI  2023-07-13T11:01:20Z           12  \n",
       "..                        ...          ...                   ...          ...  \n",
       "146  UCY6KjrDBN_tIRFT_QNqQbRQ  Madan Gowri  2017-03-28T10:03:58Z          102  \n",
       "147  UCY6KjrDBN_tIRFT_QNqQbRQ  Madan Gowri  2016-10-13T19:01:39Z          240  \n",
       "148  UCY6KjrDBN_tIRFT_QNqQbRQ  Madan Gowri  2016-09-20T16:26:29Z            2  \n",
       "149  UCY6KjrDBN_tIRFT_QNqQbRQ  Madan Gowri  2016-09-20T16:23:02Z           65  \n",
       "150  UCY6KjrDBN_tIRFT_QNqQbRQ  Madan Gowri  2016-09-20T16:03:11Z          538  \n",
       "\n",
       "[151 rows x 6 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df1.iterrows():\n",
    "        insert_query = '''INSERT into playlists(Playlist_Id,\n",
    "                                                    Title,\n",
    "                                                    Channel_Id,\n",
    "                                                    Channel_Name,\n",
    "                                                    PublishedAt,\n",
    "                                                    Video_Count)\n",
    "                                        VALUES(%s,%s,%s,%s,%s,%s)'''            \n",
    "        values =(\n",
    "                row['Playlist_Id'],\n",
    "                row['Title'],\n",
    "                row['Channel_Id'],\n",
    "                row['Channel_Name'],\n",
    "                row['PublishedAt'],\n",
    "                row['Video_Count'])\n",
    "                \n",
    "try:                     \n",
    "    cursor.execute(insert_query,values)\n",
    "    mydb.commit()    \n",
    "except:\n",
    "    st.write(\"Playlists values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Playlist_Id', 'Title', 'Channel_Id', 'Channel_Name', 'PublishedAt',\n",
       "       'Video_Count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playlists_table():\n",
    "    mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    drop_query = \"drop table if exists playlists\"\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = '''create table if not exists playlists(Playlist_Id varchar(100) primary key,\n",
    "                        Title varchar(80), \n",
    "                        Channel_Id varchar(100), \n",
    "                        Channel_Name varchar(100),\n",
    "                        PublishedAt timestamp,\n",
    "                        Video_Count int\n",
    "                        )'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"Playlists Table alredy created\")    \n",
    "\n",
    "    pl_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 =db[\"channel_details\"]\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "                pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "    df1 = pd.DataFrame(pl_list)\n",
    "    \n",
    "    for index,row in df1.iterrows():\n",
    "        insert_query = '''INSERT into playlists(Playlist_Id,\n",
    "                                                    Title,\n",
    "                                                    Channel_Id,\n",
    "                                                    Channel_Name,\n",
    "                                                    PublishedAt,\n",
    "                                                    Video_Count)\n",
    "                                        VALUES(%s,%s,%s,%s,%s,%s)'''            \n",
    "        values =(\n",
    "                row['Playlist_Id'],\n",
    "                row['Title'],\n",
    "                row['Channel_Id'],\n",
    "                row['Channel_Name'],\n",
    "                row['Published_At'],\n",
    "                row['Video_Count'])\n",
    "                \n",
    "    try:                     \n",
    "        cursor.execute(insert_query,values)\n",
    "        mydb.commit()    \n",
    "    except:\n",
    "        st.write(\"Playlists values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "drop_query = \"drop table if exists videos\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "try:\n",
    "    create_query = '''create table if not exists videos(\n",
    "                    Channel_Name varchar(150),\n",
    "                    Channel_Id varchar(100),\n",
    "                    Video_Id varchar(50) primary key, \n",
    "                    Title varchar(150), \n",
    "                    Tags text,\n",
    "                    Thumbnail varchar(225),\n",
    "                    Description text, \n",
    "                    Published_Date timestamp,\n",
    "                    Duration interval, \n",
    "                    Views bigint, \n",
    "                    Likes bigint,\n",
    "                    Comments int,\n",
    "                    Favorite_Count int, \n",
    "                    Definition varchar(10), \n",
    "                    Caption_Status varchar(50) \n",
    "                    )''' \n",
    "                    \n",
    "    cursor.execute(create_query)             \n",
    "    mydb.commit()\n",
    "except:\n",
    "    st.write(\"Videos Table alrady created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_list = []\n",
    "db = client[\"Youtube_data\"]\n",
    "coll1 = db[\"channel_details\"]\n",
    "for vi_data in coll1.find({},{\"_id\":0,\"video_information\":1}):\n",
    "    for i in range(len(vi_data[\"video_information\"])):\n",
    "        vi_list.append(vi_data[\"video_information\"][i])\n",
    "df2 = pd.DataFrame(vi_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_Name</th>\n",
       "      <th>Channel_Id</th>\n",
       "      <th>Video_Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Thumbnail</th>\n",
       "      <th>Description</th>\n",
       "      <th>Published_Date</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Favorite_Count</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Caption_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GUVI</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>JSkZtsJYCBs</td>\n",
       "      <td>I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...</td>\n",
       "      <td>[guvi, guvi coding, guvi course, guvi course r...</td>\n",
       "      <td>https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg</td>\n",
       "      <td>#shortsfeed #shortsvideo #shortsyoutube #short...</td>\n",
       "      <td>2024-01-25T13:30:13Z</td>\n",
       "      <td>PT6S</td>\n",
       "      <td>396</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GUVI</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>JSkZtsJYCBs</td>\n",
       "      <td>I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...</td>\n",
       "      <td>[guvi, guvi coding, guvi course, guvi course r...</td>\n",
       "      <td>https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg</td>\n",
       "      <td>#shortsfeed #shortsvideo #shortsyoutube #short...</td>\n",
       "      <td>2024-01-25T13:30:13Z</td>\n",
       "      <td>PT6S</td>\n",
       "      <td>396</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GUVI</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>JSkZtsJYCBs</td>\n",
       "      <td>I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...</td>\n",
       "      <td>[guvi, guvi coding, guvi course, guvi course r...</td>\n",
       "      <td>https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg</td>\n",
       "      <td>#shortsfeed #shortsvideo #shortsyoutube #short...</td>\n",
       "      <td>2024-01-25T13:30:13Z</td>\n",
       "      <td>PT6S</td>\n",
       "      <td>396</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GUVI</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>JSkZtsJYCBs</td>\n",
       "      <td>I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...</td>\n",
       "      <td>[guvi, guvi coding, guvi course, guvi course r...</td>\n",
       "      <td>https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg</td>\n",
       "      <td>#shortsfeed #shortsvideo #shortsyoutube #short...</td>\n",
       "      <td>2024-01-25T13:30:13Z</td>\n",
       "      <td>PT6S</td>\n",
       "      <td>396</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GUVI</td>\n",
       "      <td>UCduIoIMfD8tT3KoU0-zBRgQ</td>\n",
       "      <td>JSkZtsJYCBs</td>\n",
       "      <td>I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...</td>\n",
       "      <td>[guvi, guvi coding, guvi course, guvi course r...</td>\n",
       "      <td>https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg</td>\n",
       "      <td>#shortsfeed #shortsvideo #shortsyoutube #short...</td>\n",
       "      <td>2024-01-25T13:30:13Z</td>\n",
       "      <td>PT6S</td>\n",
       "      <td>396</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>l7zpYUgtzxI</td>\n",
       "      <td>Jio Story | Tamil | Madan Gowri | MG</td>\n",
       "      <td>[reliance jio, Ambani, Mukesh ambani, anil amb...</td>\n",
       "      <td>https://i.ytimg.com/vi/l7zpYUgtzxI/default.jpg</td>\n",
       "      <td>Instagram : https://www.instagram.com/madangow...</td>\n",
       "      <td>2016-09-15T15:03:53Z</td>\n",
       "      <td>PT2M36S</td>\n",
       "      <td>70076</td>\n",
       "      <td>2203</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>7lZbUPiZXbk</td>\n",
       "      <td>Jio Business explained | Tamil | Madan Gowri | MG</td>\n",
       "      <td>[Jio, Madan Gowri, Relianace Jio, Mukesh Amban...</td>\n",
       "      <td>https://i.ytimg.com/vi/7lZbUPiZXbk/default.jpg</td>\n",
       "      <td>Instagram : https://www.instagram.com/madangow...</td>\n",
       "      <td>2016-09-04T21:55:43Z</td>\n",
       "      <td>PT8M1S</td>\n",
       "      <td>202666</td>\n",
       "      <td>7523</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>sP3A_jyZOis</td>\n",
       "      <td>Pakistan Independence day  | Madan Gowri | MG</td>\n",
       "      <td>[India, Pakistan Independence day, Pakistan, M...</td>\n",
       "      <td>https://i.ytimg.com/vi/sP3A_jyZOis/default.jpg</td>\n",
       "      <td>Instagram : https://www.instagram.com/madangow...</td>\n",
       "      <td>2016-08-14T06:04:23Z</td>\n",
       "      <td>PT2M39S</td>\n",
       "      <td>147677</td>\n",
       "      <td>5050</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>16O8N3-8gsY</td>\n",
       "      <td>Fight for her | Madan Gowri | MG</td>\n",
       "      <td>[Swati Murder, Tamil Society, Tamil movies, Ta...</td>\n",
       "      <td>https://i.ytimg.com/vi/16O8N3-8gsY/default.jpg</td>\n",
       "      <td>Instagram : https://www.instagram.com/madangow...</td>\n",
       "      <td>2016-07-03T09:30:45Z</td>\n",
       "      <td>PT7M2S</td>\n",
       "      <td>419028</td>\n",
       "      <td>19555</td>\n",
       "      <td>1388</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>Madan Gowri</td>\n",
       "      <td>UCY6KjrDBN_tIRFT_QNqQbRQ</td>\n",
       "      <td>N3r1o_kfaXI</td>\n",
       "      <td>Madan Gowri First YouTube Video - Stop letting...</td>\n",
       "      <td>[Relationship, misunderstanding, life, talk]</td>\n",
       "      <td>https://i.ytimg.com/vi/N3r1o_kfaXI/default.jpg</td>\n",
       "      <td>Madan Gowri's first video on YouTube.\\n\\nA sma...</td>\n",
       "      <td>2016-03-22T20:03:59Z</td>\n",
       "      <td>PT1M40S</td>\n",
       "      <td>1133498</td>\n",
       "      <td>77497</td>\n",
       "      <td>8933</td>\n",
       "      <td>0</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3970 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel_Name                Channel_Id     Video_Id  \\\n",
       "0            GUVI  UCduIoIMfD8tT3KoU0-zBRgQ  JSkZtsJYCBs   \n",
       "1            GUVI  UCduIoIMfD8tT3KoU0-zBRgQ  JSkZtsJYCBs   \n",
       "2            GUVI  UCduIoIMfD8tT3KoU0-zBRgQ  JSkZtsJYCBs   \n",
       "3            GUVI  UCduIoIMfD8tT3KoU0-zBRgQ  JSkZtsJYCBs   \n",
       "4            GUVI  UCduIoIMfD8tT3KoU0-zBRgQ  JSkZtsJYCBs   \n",
       "...           ...                       ...          ...   \n",
       "3965  Madan Gowri  UCY6KjrDBN_tIRFT_QNqQbRQ  l7zpYUgtzxI   \n",
       "3966  Madan Gowri  UCY6KjrDBN_tIRFT_QNqQbRQ  7lZbUPiZXbk   \n",
       "3967  Madan Gowri  UCY6KjrDBN_tIRFT_QNqQbRQ  sP3A_jyZOis   \n",
       "3968  Madan Gowri  UCY6KjrDBN_tIRFT_QNqQbRQ  16O8N3-8gsY   \n",
       "3969  Madan Gowri  UCY6KjrDBN_tIRFT_QNqQbRQ  N3r1o_kfaXI   \n",
       "\n",
       "                                                  Title  \\\n",
       "0     I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...   \n",
       "1     I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...   \n",
       "2     I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...   \n",
       "3     I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...   \n",
       "4     I'm okay🥲👍| GUVI | #shortsvideo #guvi #shortsy...   \n",
       "...                                                 ...   \n",
       "3965               Jio Story | Tamil | Madan Gowri | MG   \n",
       "3966  Jio Business explained | Tamil | Madan Gowri | MG   \n",
       "3967      Pakistan Independence day  | Madan Gowri | MG   \n",
       "3968                   Fight for her | Madan Gowri | MG   \n",
       "3969  Madan Gowri First YouTube Video - Stop letting...   \n",
       "\n",
       "                                                   Tags  \\\n",
       "0     [guvi, guvi coding, guvi course, guvi course r...   \n",
       "1     [guvi, guvi coding, guvi course, guvi course r...   \n",
       "2     [guvi, guvi coding, guvi course, guvi course r...   \n",
       "3     [guvi, guvi coding, guvi course, guvi course r...   \n",
       "4     [guvi, guvi coding, guvi course, guvi course r...   \n",
       "...                                                 ...   \n",
       "3965  [reliance jio, Ambani, Mukesh ambani, anil amb...   \n",
       "3966  [Jio, Madan Gowri, Relianace Jio, Mukesh Amban...   \n",
       "3967  [India, Pakistan Independence day, Pakistan, M...   \n",
       "3968  [Swati Murder, Tamil Society, Tamil movies, Ta...   \n",
       "3969       [Relationship, misunderstanding, life, talk]   \n",
       "\n",
       "                                           Thumbnail  \\\n",
       "0     https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg   \n",
       "1     https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg   \n",
       "2     https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg   \n",
       "3     https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg   \n",
       "4     https://i.ytimg.com/vi/JSkZtsJYCBs/default.jpg   \n",
       "...                                              ...   \n",
       "3965  https://i.ytimg.com/vi/l7zpYUgtzxI/default.jpg   \n",
       "3966  https://i.ytimg.com/vi/7lZbUPiZXbk/default.jpg   \n",
       "3967  https://i.ytimg.com/vi/sP3A_jyZOis/default.jpg   \n",
       "3968  https://i.ytimg.com/vi/16O8N3-8gsY/default.jpg   \n",
       "3969  https://i.ytimg.com/vi/N3r1o_kfaXI/default.jpg   \n",
       "\n",
       "                                            Description        Published_Date  \\\n",
       "0     #shortsfeed #shortsvideo #shortsyoutube #short...  2024-01-25T13:30:13Z   \n",
       "1     #shortsfeed #shortsvideo #shortsyoutube #short...  2024-01-25T13:30:13Z   \n",
       "2     #shortsfeed #shortsvideo #shortsyoutube #short...  2024-01-25T13:30:13Z   \n",
       "3     #shortsfeed #shortsvideo #shortsyoutube #short...  2024-01-25T13:30:13Z   \n",
       "4     #shortsfeed #shortsvideo #shortsyoutube #short...  2024-01-25T13:30:13Z   \n",
       "...                                                 ...                   ...   \n",
       "3965  Instagram : https://www.instagram.com/madangow...  2016-09-15T15:03:53Z   \n",
       "3966  Instagram : https://www.instagram.com/madangow...  2016-09-04T21:55:43Z   \n",
       "3967  Instagram : https://www.instagram.com/madangow...  2016-08-14T06:04:23Z   \n",
       "3968  Instagram : https://www.instagram.com/madangow...  2016-07-03T09:30:45Z   \n",
       "3969  Madan Gowri's first video on YouTube.\\n\\nA sma...  2016-03-22T20:03:59Z   \n",
       "\n",
       "     Duration    Views  Likes Comments Favorite_Count Definition  \\\n",
       "0        PT6S      396     13        0              0         hd   \n",
       "1        PT6S      396     13        0              0         hd   \n",
       "2        PT6S      396     13        0              0         hd   \n",
       "3        PT6S      396     13        0              0         hd   \n",
       "4        PT6S      396     13        0              0         hd   \n",
       "...       ...      ...    ...      ...            ...        ...   \n",
       "3965  PT2M36S    70076   2203      153              0         hd   \n",
       "3966   PT8M1S   202666   7523      548              0         hd   \n",
       "3967  PT2M39S   147677   5050      213              0         hd   \n",
       "3968   PT7M2S   419028  19555     1388              0         hd   \n",
       "3969  PT1M40S  1133498  77497     8933              0         hd   \n",
       "\n",
       "     Caption_Status  \n",
       "0             false  \n",
       "1             false  \n",
       "2             false  \n",
       "3             false  \n",
       "4             false  \n",
       "...             ...  \n",
       "3965          false  \n",
       "3966          false  \n",
       "3967          false  \n",
       "3968          false  \n",
       "3969          false  \n",
       "\n",
       "[3970 rows x 15 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Channel_Name', 'Channel_Id', 'Video_Id', 'Title', 'Tags', 'Thumbnail',\n",
       "       'Description', 'Published_Date', 'Duration', 'Views', 'Likes',\n",
       "       'Comments', 'Favorite_Count', 'Definition', 'Caption_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df2.iterrows():\n",
    "    insert_query = '''\n",
    "                INSERT INTO videos (Channel_Name,\n",
    "                    Channel_Id,\n",
    "                    Video_Id, \n",
    "                    Title, \n",
    "                    Tags,\n",
    "                    Thumbnail,\n",
    "                    Description, \n",
    "                    Published_Date,\n",
    "                    Duration, \n",
    "                    Views, \n",
    "                    Likes,\n",
    "                    Comments,\n",
    "                    Favorite_Count, \n",
    "                    Definition, \n",
    "                    Caption_Status \n",
    "                    )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\n",
    "            '''\n",
    "    values = (\n",
    "                row['Channel_Name'],\n",
    "                row['Channel_Id'],\n",
    "                row['Video_Id'],\n",
    "                row['Title'],\n",
    "                row['Tags'],\n",
    "                row['Thumbnail'],\n",
    "                row['Description'],\n",
    "                row['Published_Date'],\n",
    "                row['Duration'],\n",
    "                row['Views'],\n",
    "                row['Likes'],\n",
    "                row['Comments'],\n",
    "                row['Favorite_Count'],\n",
    "                row['Definition'],\n",
    "                row['Caption_Status'])\n",
    "                            \n",
    "try:    \n",
    "    cursor.execute(insert_query,values)\n",
    "    mydb.commit()\n",
    "except:\n",
    "    st.write(\"videos values already inserted in the table\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videos_table():\n",
    "\n",
    "    mydb = psycopg2.connect(host=\"localhost\",\n",
    "                user=\"postgres\",\n",
    "                password=\"nithya\",\n",
    "                database= \"youtube_data\",\n",
    "                port = \"5432\"\n",
    "                )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    drop_query = \"drop table if exists videos\"\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = '''create table if not exists videos(\n",
    "                        Channel_Name varchar(150),\n",
    "                        Channel_Id varchar(100),\n",
    "                        Video_Id varchar(50) primary key, \n",
    "                        Title varchar(150), \n",
    "                        Tags text,\n",
    "                        Thumbnail varchar(225),\n",
    "                        Description text, \n",
    "                        Published_Date timestamp,\n",
    "                        Duration interval, \n",
    "                        Views bigint, \n",
    "                        Likes bigint,\n",
    "                        Comments int,\n",
    "                        Favorite_Count int, \n",
    "                        Definition varchar(10), \n",
    "                        Caption_Status varchar(50) \n",
    "                        )''' \n",
    "                        \n",
    "        cursor.execute(create_query)             \n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"Videos Table alrady created\")\n",
    "\n",
    "    vi_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for vi_data in coll1.find({},{\"_id\":0,\"video_information\":1}):\n",
    "        for i in range(len(vi_data[\"video_information\"])):\n",
    "            vi_list.append(vi_data[\"video_information\"][i])\n",
    "    df2 = pd.DataFrame(vi_list)\n",
    "        \n",
    "    \n",
    "    for index, row in df2.iterrows():\n",
    "        insert_query = '''\n",
    "                    INSERT INTO videos (Channel_Name,\n",
    "                        Channel_Id,\n",
    "                        Video_Id, \n",
    "                        Title, \n",
    "                        Tags,\n",
    "                        Thumbnail,\n",
    "                        Description, \n",
    "                        Published_Date,\n",
    "                        Duration, \n",
    "                        Views, \n",
    "                        Likes,\n",
    "                        Comments,\n",
    "                        Favorite_Count, \n",
    "                        Definition, \n",
    "                        Caption_Status \n",
    "                        )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\n",
    "                '''\n",
    "        values = (\n",
    "                    row['Channel_Name'],\n",
    "                    row['Channel_Id'],\n",
    "                    row['Video_Id'],\n",
    "                    row['Title'],\n",
    "                    row['Tags'],\n",
    "                    row['Thumbnail'],\n",
    "                    row['Description'],\n",
    "                    row['Published_Date'],\n",
    "                    row['Duration'],\n",
    "                    row['Views'],\n",
    "                    row['Likes'],\n",
    "                    row['Comments'],\n",
    "                    row['Favorite_Count'],\n",
    "                    row['Definition'],\n",
    "                    row['Caption_Status'])\n",
    "                                \n",
    "    try:    \n",
    "        cursor.execute(insert_query,values)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"videos values already inserted in the table\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "drop_query = \"drop table if exists comments\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "try:\n",
    "    create_query = '''CREATE TABLE if not exists comments(Comment_Id varchar(100) primary key,\n",
    "                    Video_Id varchar(80),\n",
    "                    Comment_Text text, \n",
    "                    Comment_Author varchar(150),\n",
    "                    Comment_Published timestamp)'''\n",
    "    cursor.execute(create_query)\n",
    "    mydb.commit()\n",
    "    \n",
    "except:\n",
    "    st.write(\"Commentsp Table already created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_list = []\n",
    "db = client[\"Youtube_data\"]\n",
    "coll1 = db[\"channel_details\"]\n",
    "for com_data in coll1.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "    for i in range(len(com_data[\"comment_information\"])):\n",
    "        com_list.append(com_data[\"comment_information\"][i])\n",
    "df3 = pd.DataFrame(com_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_Id</th>\n",
       "      <th>Video_Id</th>\n",
       "      <th>Comment_Text</th>\n",
       "      <th>Comment_Author</th>\n",
       "      <th>Comment_Published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgzfrP619_nL6iFY7xV4AaABAg</td>\n",
       "      <td>V4Zpgu4ymn0</td>\n",
       "      <td>😂😂😂</td>\n",
       "      <td>@awakenworld1</td>\n",
       "      <td>2023-08-05T09:08:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugz-7ZDSb46jxuDF9DJ4AaABAg</td>\n",
       "      <td>V4Zpgu4ymn0</td>\n",
       "      <td>Your have Seprate deparment of meme creators😂😂</td>\n",
       "      <td>@maheshwaran6301</td>\n",
       "      <td>2023-08-05T08:00:05Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgzfrP619_nL6iFY7xV4AaABAg</td>\n",
       "      <td>V4Zpgu4ymn0</td>\n",
       "      <td>😂😂😂</td>\n",
       "      <td>@awakenworld1</td>\n",
       "      <td>2023-08-05T09:08:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugz-7ZDSb46jxuDF9DJ4AaABAg</td>\n",
       "      <td>V4Zpgu4ymn0</td>\n",
       "      <td>Your have Seprate deparment of meme creators😂😂</td>\n",
       "      <td>@maheshwaran6301</td>\n",
       "      <td>2023-08-05T08:00:05Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UgzfrP619_nL6iFY7xV4AaABAg</td>\n",
       "      <td>V4Zpgu4ymn0</td>\n",
       "      <td>😂😂😂</td>\n",
       "      <td>@awakenworld1</td>\n",
       "      <td>2023-08-05T09:08:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23295</th>\n",
       "      <td>Ugy-8WY688ACunxngMp4AaABAg</td>\n",
       "      <td>Bp_4-uheCD8</td>\n",
       "      <td>8:58 this place reminds me of the *Mirror* mov...</td>\n",
       "      <td>@hathijafathima2153</td>\n",
       "      <td>2023-05-02T16:04:36Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23296</th>\n",
       "      <td>UgwjdXB0ERk_aduosl14AaABAg</td>\n",
       "      <td>Bp_4-uheCD8</td>\n",
       "      <td>Avlo periya vishayam ilaye</td>\n",
       "      <td>@starsaran25</td>\n",
       "      <td>2023-05-02T15:10:03Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23297</th>\n",
       "      <td>UgwNdUacn9kZp7yicZ14AaABAg</td>\n",
       "      <td>Bp_4-uheCD8</td>\n",
       "      <td>All those ideas and architecture has been copi...</td>\n",
       "      <td>@mahadevan1561</td>\n",
       "      <td>2023-05-02T14:26:22Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23298</th>\n",
       "      <td>UgyyoAn-Fyzehg7w6cV4AaABAg</td>\n",
       "      <td>Bp_4-uheCD8</td>\n",
       "      <td>Awesome\\nBro!</td>\n",
       "      <td>@georgea3356</td>\n",
       "      <td>2023-05-02T13:11:35Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23299</th>\n",
       "      <td>Ugyv-ZWEACSEOLnPEeF4AaABAg</td>\n",
       "      <td>Bp_4-uheCD8</td>\n",
       "      <td>😱😱😱😱</td>\n",
       "      <td>@haneefparnambattuking7188</td>\n",
       "      <td>2023-05-02T12:47:12Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Comment_Id     Video_Id  \\\n",
       "0      UgzfrP619_nL6iFY7xV4AaABAg  V4Zpgu4ymn0   \n",
       "1      Ugz-7ZDSb46jxuDF9DJ4AaABAg  V4Zpgu4ymn0   \n",
       "2      UgzfrP619_nL6iFY7xV4AaABAg  V4Zpgu4ymn0   \n",
       "3      Ugz-7ZDSb46jxuDF9DJ4AaABAg  V4Zpgu4ymn0   \n",
       "4      UgzfrP619_nL6iFY7xV4AaABAg  V4Zpgu4ymn0   \n",
       "...                           ...          ...   \n",
       "23295  Ugy-8WY688ACunxngMp4AaABAg  Bp_4-uheCD8   \n",
       "23296  UgwjdXB0ERk_aduosl14AaABAg  Bp_4-uheCD8   \n",
       "23297  UgwNdUacn9kZp7yicZ14AaABAg  Bp_4-uheCD8   \n",
       "23298  UgyyoAn-Fyzehg7w6cV4AaABAg  Bp_4-uheCD8   \n",
       "23299  Ugyv-ZWEACSEOLnPEeF4AaABAg  Bp_4-uheCD8   \n",
       "\n",
       "                                            Comment_Text  \\\n",
       "0                                                    😂😂😂   \n",
       "1         Your have Seprate deparment of meme creators😂😂   \n",
       "2                                                    😂😂😂   \n",
       "3         Your have Seprate deparment of meme creators😂😂   \n",
       "4                                                    😂😂😂   \n",
       "...                                                  ...   \n",
       "23295  8:58 this place reminds me of the *Mirror* mov...   \n",
       "23296                         Avlo periya vishayam ilaye   \n",
       "23297  All those ideas and architecture has been copi...   \n",
       "23298                                      Awesome\\nBro!   \n",
       "23299                                               😱😱😱😱   \n",
       "\n",
       "                   Comment_Author     Comment_Published  \n",
       "0                   @awakenworld1  2023-08-05T09:08:54Z  \n",
       "1                @maheshwaran6301  2023-08-05T08:00:05Z  \n",
       "2                   @awakenworld1  2023-08-05T09:08:54Z  \n",
       "3                @maheshwaran6301  2023-08-05T08:00:05Z  \n",
       "4                   @awakenworld1  2023-08-05T09:08:54Z  \n",
       "...                           ...                   ...  \n",
       "23295         @hathijafathima2153  2023-05-02T16:04:36Z  \n",
       "23296                @starsaran25  2023-05-02T15:10:03Z  \n",
       "23297              @mahadevan1561  2023-05-02T14:26:22Z  \n",
       "23298                @georgea3356  2023-05-02T13:11:35Z  \n",
       "23299  @haneefparnambattuking7188  2023-05-02T12:47:12Z  \n",
       "\n",
       "[23300 rows x 5 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Comment_Id', 'Video_Id', 'Comment_Text', 'Comment_Author',\n",
       "       'Comment_Published'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df3.iterrows():\n",
    "        insert_query = '''\n",
    "            INSERT INTO comments (Comment_Id,\n",
    "                                    Video_Id ,\n",
    "                                    Comment_Text,\n",
    "                                    Comment_Author,\n",
    "                                    Comment_Published)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "\n",
    "        '''\n",
    "        values = (\n",
    "            row['Comment_Id'],\n",
    "            row['Video_Id'],\n",
    "            row['Comment_Text'],\n",
    "            row['Comment_Author'],\n",
    "            row['Comment_Published']\n",
    "        )\n",
    "try:\n",
    "    cursor.execute(insert_query,values)\n",
    "    mydb.commit()\n",
    "except:\n",
    "    st.write(\"This comments are already exist in comments table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comments_table():\n",
    "    \n",
    "    mydb = psycopg2.connect(host=\"localhost\",\n",
    "                user=\"postgres\",\n",
    "                password=\"nithya\",\n",
    "                database= \"youtube_data\",\n",
    "                port = \"5432\"\n",
    "                )\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    drop_query = \"drop table if exists comments\"\n",
    "    cursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE if not exists comments(Comment_Id varchar(100) primary key,\n",
    "                       Video_Id varchar(80),\n",
    "                       Comment_Text text, \n",
    "                       Comment_Author varchar(150),\n",
    "                       Comment_Published timestamp)'''\n",
    "        cursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "        \n",
    "    except:\n",
    "        st.write(\"Commentsp Table already created\")\n",
    "\n",
    "    com_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for com_data in coll1.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "        for i in range(len(com_data[\"comment_information\"])):\n",
    "            com_list.append(com_data[\"comment_information\"][i])\n",
    "    df3 = pd.DataFrame(com_list)\n",
    "\n",
    "\n",
    "    for index, row in df3.iterrows():\n",
    "            insert_query = '''\n",
    "                INSERT INTO comments (Comment_Id,\n",
    "                                      Video_Id ,\n",
    "                                      Comment_Text,\n",
    "                                      Comment_Author,\n",
    "                                      Comment_Published)\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "\n",
    "            '''\n",
    "            values = (\n",
    "                row['Comment_Id'],\n",
    "                row['Video_Id'],\n",
    "                row['Comment_Text'],\n",
    "                row['Comment_Author'],\n",
    "                row['Comment_Published']\n",
    "            )\n",
    "    try:\n",
    "        cursor.execute(insert_query,values)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"This comments are already exist in comments table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables():\n",
    "    channels_table()\n",
    "    playlists_table()\n",
    "    videos_table()\n",
    "    comments_table()\n",
    "    return \"Tables Created successfully\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channels_table():\n",
    "    ch_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"] \n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"channel_information\"])\n",
    "    channels_table = st.dataframe(ch_list)\n",
    "    return channels_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_playlists_table():\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll1 =db[\"channel_details\"]\n",
    "    pl_list = []\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"playlist_information\"])):\n",
    "                pl_list.append(pl_data[\"playlist_information\"][i])\n",
    "    playlists_table = st.dataframe(pl_list)\n",
    "    return playlists_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_videos_table():\n",
    "    vi_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll2 = db[\"channel_details\"]\n",
    "    for vi_data in coll2.find({},{\"_id\":0,\"video_information\":1}):\n",
    "        for i in range(len(vi_data[\"video_information\"])):\n",
    "            vi_list.append(vi_data[\"video_information\"][i])\n",
    "    videos_table = st.dataframe(vi_list)\n",
    "    return videos_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comments_table():\n",
    "    com_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    coll3 = db[\"channel_details\"]\n",
    "    for com_data in coll3.find({},{\"_id\":0,\"comment_information\":1}):\n",
    "        for i in range(len(com_data[\"comment_information\"])):\n",
    "            com_list.append(com_data[\"comment_information\"][i])\n",
    "    comments_table = st.dataframe(com_list)\n",
    "    return comments_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "with st.sidebar:\n",
    "    st.title(\":blue[YOUTUBE DATA HARVESTING AND WAREHOUSING]\")\n",
    "    st.header(\"SKILL TAKE AWAY\")\n",
    "    st.caption('Python scripting')\n",
    "    st.caption(\"Data Collection\")\n",
    "    st.caption(\"MongoDB\")\n",
    "    st.caption(\"API Integration\")\n",
    "    st.caption(\" Data Managment using MongoDB and SQL\")\n",
    "    \n",
    "channel_id = st.text_input(\"Enter the Channel id\")\n",
    "channels = channel_id.split(',')\n",
    "channels = [ch.strip() for ch in channels if ch]\n",
    "\n",
    "if st.button(\"Collect and Store data\"):\n",
    "    for channel in channels:\n",
    "        ch_ids = []\n",
    "        db = client[\"Youtube_data\"]\n",
    "        coll1 = db[\"channel_details\"]\n",
    "        for ch_data in coll1.find({},{\"_id\":0,\"channel_information\":1}):\n",
    "            ch_ids.append(ch_data[\"channel_information\"][\"Channel_Id\"])\n",
    "        if channel in ch_ids:\n",
    "            st.success(\"Channel details of the given channel id: \" + channel + \" already exists\")\n",
    "        else:\n",
    "            output = channel_details(channel)\n",
    "            st.success(output)\n",
    "            \n",
    "if st.button(\"Migrate to SQL\"):\n",
    "    display = tables()\n",
    "    st.success(display)\n",
    "    \n",
    "show_table = st.radio(\"SELECT THE TABLE FOR VIEW\",(\":green[channels]\",\":orange[playlists]\",\":red[videos]\",\":blue[comments]\"))\n",
    "\n",
    "if show_table == \":green[channels]\":\n",
    "    show_channels_table()\n",
    "elif show_table == \":orange[playlists]\":\n",
    "    show_playlists_table()\n",
    "elif show_table ==\":red[videos]\":\n",
    "    show_videos_table()\n",
    "elif show_table == \":blue[comments]\":\n",
    "    show_comments_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query1 = \"select Title as videos, Channel_Name as ChannelName from videos;\"\n",
    "cursor.execute(query1)\n",
    "mydb.commit()\n",
    "t1=cursor.fetchall()\n",
    "st.write(pd.DataFrame(t1, columns=[\"Video Title\",\"Channel Name\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query2 = \"select Channel_Name as ChannelName, Total_vedio as NO_Videos from channels order by Total_vedio desc;\"\n",
    "cursor.execute(query2)\n",
    "mydb.commit()\n",
    "t2=cursor.fetchall()\n",
    "st.write(pd.DataFrame(t2, columns=[\"Channel Name\",\"No Of Videos\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "query3 = '''select Views as views , Channel_Name as ChannelName,Title as VideoTitle from videos \n",
    "                    where Views is not null order by Views desc limit 10;'''\n",
    "cursor.execute(query3)\n",
    "mydb.commit()\n",
    "t3 = cursor.fetchall()\n",
    "st.write(pd.DataFrame(t3, columns = [\"views\",\"channel Name\",\"video title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query4 = \"select Comments as No_comments ,Title as VideoTitle from videos where Comments is not null;\"\n",
    "cursor.execute(query4)\n",
    "mydb.commit()\n",
    "t4=cursor.fetchall()\n",
    "st.write(pd.DataFrame(t4, columns=[\"No Of Comments\", \"Video Title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query5 = '''select Title as VideoTitle, Channel_Name as ChannelName, Likes as LikesCount from videos \n",
    "                       where Likes is not null order by Likes desc;'''\n",
    "cursor.execute(query5)\n",
    "mydb.commit()\n",
    "t5 = cursor.fetchall()\n",
    "st.write(pd.DataFrame(t5, columns=[\"video Title\",\"channel Name\",\"like count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query6 = '''select Likes as likeCount,Title as VideoTitle from videos;'''\n",
    "cursor.execute(query6)\n",
    "mydb.commit()\n",
    "t6 = cursor.fetchall()\n",
    "st.write(pd.DataFrame(t6, columns=[\"like count\",\"video title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query7 = \"select Channel_Name as ChannelName, Views as Channelviews from channels;\"\n",
    "cursor.execute(query7)\n",
    "mydb.commit()\n",
    "t7=cursor.fetchall()\n",
    "st.write(pd.DataFrame(t7, columns=[\"channel name\",\"total views\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query8 = '''select Title as Video_Title, Published_Date as VideoRelease, Channel_Name as ChannelName from videos \n",
    "                where extract(year from Published_Date) = 2022;'''\n",
    "cursor.execute(query8)\n",
    "mydb.commit()\n",
    "t8=cursor.fetchall()\n",
    "st.write(pd.DataFrame(t8,columns=[\"Name\", \"Video Publised On\", \"ChannelName\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query9 =  \"SELECT Channel_Name as ChannelName, AVG(Duration) AS average_duration FROM videos GROUP BY Channel_Name;\"\n",
    "cursor.execute(query9)\n",
    "mydb.commit()\n",
    "t9=cursor.fetchall()\n",
    "t9 = pd.DataFrame(t9, columns=['ChannelTitle', 'Average Duration'])\n",
    "T9=[]\n",
    "for index, row in t9.iterrows():\n",
    "    channel_title = row['ChannelTitle']\n",
    "    average_duration = row['Average Duration']\n",
    "    average_duration_str = str(average_duration)\n",
    "    T9.append({\"Channel Title\": channel_title ,  \"Average Duration\": average_duration_str})\n",
    "st.write(pd.DataFrame(T9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "query10 = '''select Title as VideoTitle, Channel_Name as ChannelName, Comments as Comments from videos \n",
    "                       where Comments is not null order by Comments desc;'''\n",
    "cursor.execute(query10)\n",
    "mydb.commit()\n",
    "t10=cursor.fetchall()\n",
    "st.write(pd.DataFrame(t10, columns=['Video Title', 'Channel Name', 'NO Of Comments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL connection\n",
    "mydb = psycopg2.connect(host=\"localhost\",\n",
    "            user=\"postgres\",\n",
    "            password=\"nithya\",\n",
    "            database= \"youtube_data\",\n",
    "            port = \"5432\"\n",
    "            )\n",
    "cursor = mydb.cursor()\n",
    "    \n",
    "question = st.selectbox(\n",
    "    'Please Select Your Question',\n",
    "    ('1. All the videos and the Channel Name',\n",
    "     '2. Channels with most number of videos',\n",
    "     '3. 10 most viewed videos',\n",
    "     '4. Comments in each video',\n",
    "     '5. Videos with highest likes',\n",
    "     '6. likes of all videos',\n",
    "     '7. views of each channel',\n",
    "     '8. videos published in the year 2022',\n",
    "     '9. average duration of all videos in each channel',\n",
    "     '10. videos with highest number of comments'))\n",
    "\n",
    "     \n",
    "if question == '1. All the videos and the Channel Name':\n",
    "    query1 = \"select Title as videos, Channel_Name as ChannelName from videos;\"\n",
    "    cursor.execute(query1)\n",
    "    mydb.commit()\n",
    "    t1=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t1, columns=[\"Video Title\",\"Channel Name\"]))\n",
    "\n",
    "elif question == '2. Channels with most number of videos':\n",
    "    query2 = \"select Channel_Name as ChannelName, Total_vedio as NO_Videos from channels order by Total_vedio desc;\"\n",
    "    cursor.execute(query2)\n",
    "    mydb.commit()\n",
    "    t2=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t2, columns=[\"Channel Name\",\"No Of Videos\"]))\n",
    "\n",
    "elif question == '3. 10 most viewed videos':\n",
    "    query3 = '''select Views as views , Channel_Name as ChannelName,Title as VideoTitle from videos \n",
    "                        where Views is not null order by Views desc limit 10;'''\n",
    "    cursor.execute(query3)\n",
    "    mydb.commit()\n",
    "    t3 = cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t3, columns = [\"views\",\"channel Name\",\"video title\"]))\n",
    "\n",
    "elif question == '4. Comments in each video':\n",
    "    query4 = \"select Comments as No_comments ,Title as VideoTitle from videos where Comments is not null;\"\n",
    "    cursor.execute(query4)\n",
    "    mydb.commit()\n",
    "    t4=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t4, columns=[\"No Of Comments\", \"Video Title\"]))\n",
    "\n",
    "elif question == '5. Videos with highest likes':\n",
    "    query5 = '''select Title as VideoTitle, Channel_Name as ChannelName, Likes as LikesCount from videos \n",
    "                       where Likes is not null order by Likes desc;'''\n",
    "    cursor.execute(query5)\n",
    "    mydb.commit()\n",
    "    t5 = cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t5, columns=[\"video Title\",\"channel Name\",\"like count\"]))\n",
    "\n",
    "elif question == '6. likes of all videos':\n",
    "    query6 = '''select Likes as likeCount,Title as VideoTitle from videos;'''\n",
    "    cursor.execute(query6)\n",
    "    mydb.commit()\n",
    "    t6 = cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t6, columns=[\"like count\",\"video title\"]))\n",
    "\n",
    "elif question == '7. views of each channel':\n",
    "    query7 = \"select Channel_Name as ChannelName, Views as Channelviews from channels;\"\n",
    "    cursor.execute(query7)\n",
    "    mydb.commit()\n",
    "    t7=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t7, columns=[\"channel name\",\"total views\"]))\n",
    "\n",
    "elif question == '8. videos published in the year 2022':\n",
    "    query8 = '''select Title as Video_Title, Published_Date as VideoRelease, Channel_Name as ChannelName from videos \n",
    "                where extract(year from Published_Date) = 2022;'''\n",
    "    cursor.execute(query8)\n",
    "    mydb.commit()\n",
    "    t8=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t8,columns=[\"Name\", \"Video Publised On\", \"ChannelName\"]))\n",
    "\n",
    "elif question == '9. average duration of all videos in each channel':\n",
    "    query9 =  \"SELECT Channel_Name as ChannelName, AVG(Duration) AS average_duration FROM videos GROUP BY Channel_Name;\"\n",
    "    cursor.execute(query9)\n",
    "    mydb.commit()\n",
    "    t9=cursor.fetchall()\n",
    "    t9 = pd.DataFrame(t9, columns=['ChannelTitle', 'Average Duration'])\n",
    "    T9=[]\n",
    "    for index, row in t9.iterrows():\n",
    "        channel_title = row['ChannelTitle']\n",
    "        average_duration = row['Average Duration']\n",
    "        average_duration_str = str(average_duration)\n",
    "        T9.append({\"Channel Title\": channel_title ,  \"Average Duration\": average_duration_str})\n",
    "    st.write(pd.DataFrame(T9))\n",
    "\n",
    "elif question == '10. videos with highest number of comments':\n",
    "    query10 = '''select Title as VideoTitle, Channel_Name as ChannelName, Comments as Comments from videos \n",
    "                       where Comments is not null order by Comments desc;'''\n",
    "    cursor.execute(query10)\n",
    "    mydb.commit()\n",
    "    t10=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t10, columns=['Video Title', 'Channel Name', 'NO Of Comments']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
